{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT - A partir de 1 product_id o programa gera os 3 produtos mais semelhantes da Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c372a0504a41aca5f7ccf79980be21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding produtos:   0%|          | 0/1465 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Embeddings salvos em bert_product_embeddings.npy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "\n",
    "# 1) Carrega o DataFrame e seleciona colunas\n",
    "df = pd.read_csv('amazon.csv')  # ajuste o caminho\n",
    "df = df[['product_id', 'product_name', 'category', 'about_product']]\n",
    "\n",
    "# 2) Monta texto combinado\n",
    "def combine_text(row):\n",
    "    parts = []\n",
    "    for col in ['product_name', 'category', 'about_product']:\n",
    "        if isinstance(row[col], str) and row[col].strip():\n",
    "            parts.append(row[col].strip())\n",
    "    return \" \".join(parts)\n",
    "\n",
    "df['combined_text'] = df.apply(combine_text, axis=1)\n",
    "\n",
    "# 3) Inicializa BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model     = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "\n",
    "# 4) Função para gerar embedding CLS\n",
    "def get_embedding(text: str):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True,\n",
    "                       truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state[0, 0].cpu().numpy()\n",
    "\n",
    "# 5) Gera embeddings e salva em .npy\n",
    "embeddings = []\n",
    "for txt in tqdm(df['combined_text'], desc='Embedding produtos'):\n",
    "    embeddings.append(get_embedding(txt))\n",
    "embeddings = np.vstack(embeddings)\n",
    "np.save('bert_product_embeddings.npy', embeddings)\n",
    "\n",
    "# 6) (Opcional) salve também o DataFrame reduzido para referência\n",
    "df[['product_id']].to_parquet('df_product_ids.parquet', index=False)\n",
    "\n",
    "print(\"✅ Embeddings salvos em bert_product_embeddings.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "# 1) Recarrega o DataFrame mínimo com IDs e nomes\n",
    "df_prod = pd.read_csv('amazon.csv')  # deve conter colunas product_id, product_name\n",
    "\n",
    "ids   = df_prod['product_id'].values\n",
    "names = df_prod['product_name'].values\n",
    "\n",
    "# 2) Carrega os embeddings pré-computados\n",
    "embeddings = np.load('bert_product_embeddings.npy')\n",
    "\n",
    "# 3) Mapeia product_id → índice\n",
    "id_to_idx = {pid: i for i, pid in enumerate(ids)}\n",
    "\n",
    "# 4) Função de busca que retorna um DataFrame com ID + nome\n",
    "def find_similar_products(query_id, embeddings, id_to_idx, df_prod, top_k=3):\n",
    "    if query_id not in id_to_idx:\n",
    "        raise KeyError(f\"Product ID {query_id} não encontrado.\")\n",
    "    idx = id_to_idx[query_id]\n",
    "    q_emb = embeddings[idx].reshape(1, -1)\n",
    "    dists = cosine_distances(q_emb, embeddings)[0]\n",
    "    dists[idx] = np.inf\n",
    "    nearest = np.argsort(dists)[:top_k]\n",
    "    # monta o resultado com ID e nome\n",
    "    return df_prod.iloc[nearest][['product_id', 'product_name']].reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_id  \\\n",
      "0  B098NS6PVG   \n",
      "1  B098NS6PVG   \n",
      "2  B082LSVT4B   \n",
      "\n",
      "                                                                                                                                                                                        product_name  \n",
      "0  Ambrane Unbreakable 60W / 3A Fast Charging 1.5m Braided Type C Cable for Smartphones, Tablets, Laptops & other Type C devices, PD Technology, 480Mbps Data Sync, Quick Charge 3.0 (RCT15A, Black)  \n",
      "1  Ambrane Unbreakable 60W / 3A Fast Charging 1.5m Braided Type C Cable for Smartphones, Tablets, Laptops & other Type C devices, PD Technology, 480Mbps Data Sync, Quick Charge 3.0 (RCT15A, Black)  \n",
      "2          Ambrane Unbreakable 60W / 3A Fast Charging 1.5m Braided Type C to Type C Cable for Smartphones, Tablets, Laptops & Other Type C Devices, PD Technology, 480Mbps Data Sync (RCTT15, Black)  \n"
     ]
    }
   ],
   "source": [
    "# 5) Uso\n",
    "consulta = \"B098NS6PVG\"  # troque pelo product_id desejado\n",
    "top3_df = find_similar_products(consulta, embeddings, id_to_idx, df_prod, top_k=3)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', 200)\n",
    "print(top3_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
